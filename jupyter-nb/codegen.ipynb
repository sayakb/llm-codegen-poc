{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular Component Generator\n",
    "\n",
    "This notebook leverages the \"Titan Text G1 - Premier\" foundational model and the \"Titan Embeddings G1 - Text\" embeddings model to analyze the code structure of this application. By using these models, we aim to generate a new Angular component that adheres to the proprietary tooling and best practices observed in the existing codebase. This process demonstrates the capability of fine-tuning a model to follow specific development conventions and incorporate them into the generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "This section initializes all libraries and creates an instance of the AWS BedRock boto3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Analyze Angular Components\n",
    "\n",
    "This loads the Angular components from subdirectories within the `app` folder and uses the embeddings model to analyze their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "def load_all_files_recursive(directory):\n",
    "    documents = []\n",
    "    subfolders = set()  # Set to store unique subfolder names\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip hidden subfolders\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            try:\n",
    "                loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "                loaded_docs = loader.load()\n",
    "                # Filter out empty documents\n",
    "                non_empty_docs = [doc for doc in loaded_docs if doc.page_content.strip()]\n",
    "                documents.extend(non_empty_docs)\n",
    "                print(f\"Parsed file {filepath}\")\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Skipping binary file or file with unknown encoding: {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {filepath}: {e}\")\n",
    "\n",
    "        # Add subfolder names to the set\n",
    "        for subfolder in dirs:\n",
    "            subfolders.add(os.path.relpath(os.path.join(root, subfolder), directory))\n",
    "    return documents, \", \".join(sorted(subfolders))\n",
    "\n",
    "# Load ALL files recursively\n",
    "documents, subfolders = load_all_files_recursive(\"../src/app\")\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "# Create embeddings\n",
    "br_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)\n",
    "\n",
    "# Create vector store\n",
    "vectorstore_faiss = FAISS.from_documents(documents, embedding=br_embeddings)\n",
    "print(\"Vector store created.\")\n",
    "\n",
    "# List all subfolders\n",
    "print(f\"\\nSubfolders: {subfolders}\")\n",
    "\n",
    "# List all documents loaded to the vector store\n",
    "print(\"\\n--- Documents in Vector Store ---\")\n",
    "for doc in documents:\n",
    "    print(f\"Document Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "print(\"--- End of Documents in Vector Store ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate a New Component\n",
    "\n",
    "This section uses the foundational model to generate a new Angular component based on the analysis stored in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Initialize chat model\n",
    "chat_model = ChatBedrock(model_id=\"amazon.titan-text-premier-v1:0\", client=bedrock_client)\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for generating Angular components. \"\n",
    "    \"Generate the component based on the human prompts. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Define human prompt\n",
    "human_prompt = (\n",
    "    \"Generate a component called with the name lava_flow. \"\n",
    "    \"Use every single file within the \" + subfolders + \" and no other files \"\n",
    "    \"from the context as a boilerplate for generating the component code. Ensure that \"\n",
    "    \"the generated component has every single file that the boilerplate \"\n",
    "    \"components have. Only output the filenames and their contents. \"\n",
    "    \"Do not output anything else.\"\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create retrieval chain\n",
    "retriever = vectorstore_faiss.as_retriever()\n",
    "question_answer_chain = create_stuff_documents_chain(chat_model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": human_prompt})\n",
    "\n",
    "# Display the generated code in the specified format\n",
    "generated_code = response['answer']\n",
    "\n",
    "# Final generated code\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through adequate tuning, the model successfully generated code that adheres to the established boilerplate. This approach can be seamlessly extended to various types of codebases, including web, mobile, APIs, and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
