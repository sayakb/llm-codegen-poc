{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular Component Generator\n",
    "\n",
    "This notebook leverages an embeddings model to analyze the code structure of this application, and generates a new Angular component with a foundational model that adheres to the proprietary tooling and best practices observed in the existing codebase. \n",
    "\n",
    "By using LangChain to manage prompt templates and employing Retrieval-Augmented Generation (RAG) to provide context around embeddings, we ensure that the generated code is both relevant and aligned with the existing codebase. This process demonstrates the capability of fine-tuning a model to follow specific development conventions and incorporate them into the generated code.\n",
    "\n",
    "To run this notebook, ensure you have access to the following models within Bedrock:\n",
    "- **Titan Text G1 - Premier**\n",
    "- **Titan Embeddings G1 - Text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "This section initializes all libraries and creates an instance of the AWS BedRock boto3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Analyze Angular Components\n",
    "\n",
    "This loads the Angular components from subdirectories within the `app` folder and uses the embeddings model to analyze their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "def load_all_files_recursive(directory):\n",
    "    documents = []\n",
    "    subfolders = set()  # Set to store unique subfolder names\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip hidden subfolders\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            try:\n",
    "                loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "                loaded_docs = loader.load()\n",
    "                # Filter out empty documents\n",
    "                non_empty_docs = [doc for doc in loaded_docs if doc.page_content.strip()]\n",
    "                documents.extend(non_empty_docs)\n",
    "                print(f\"Parsed file {filepath}\")\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Skipping binary file or file with unknown encoding: {filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {filepath}: {e}\")\n",
    "\n",
    "        # Add subfolder names to the set\n",
    "        for subfolder in dirs:\n",
    "            subfolders.add(os.path.relpath(os.path.join(root, subfolder), directory))\n",
    "    return documents, \", \".join(sorted(subfolders))\n",
    "\n",
    "# Load ALL files recursively\n",
    "documents, subfolders = load_all_files_recursive(\"../src/app\")\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "# Create embeddings\n",
    "br_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)\n",
    "\n",
    "# Create vector store\n",
    "vectorstore_faiss = FAISS.from_documents(documents, embedding=br_embeddings)\n",
    "print(\"Vector store created.\")\n",
    "\n",
    "# List all subfolders\n",
    "print(f\"\\nSubfolders: {subfolders}\")\n",
    "\n",
    "# List all documents loaded to the vector store\n",
    "print(\"\\n--- Documents in Vector Store ---\")\n",
    "for doc in documents:\n",
    "    print(f\"Document Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "print(\"--- End of Documents in Vector Store ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate a New Component\n",
    "\n",
    "This section uses the foundational model to generate a new Angular component based on the analysis stored in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Initialize chat model\n",
    "chat_model = ChatBedrock(model_id=\"amazon.titan-text-premier-v1:0\", client=bedrock_client)\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for generating Angular components. \"\n",
    "    \"Generate the component code using the following context:\"\n",
    "    \"\\\\n\\\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create retrieval chain\n",
    "retriever = vectorstore_faiss.as_retriever()\n",
    "question_answer_chain = create_stuff_documents_chain(chat_model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Define ChatUX class\n",
    "class ChatUX:\n",
    "    \"\"\" A chat UX using IPWidgets \"\"\"\n",
    "    def __init__(self, rag_chain):\n",
    "        self.rag_chain = rag_chain\n",
    "        self.name = None\n",
    "        self.btn = None\n",
    "        self.out = ipw.Output()\n",
    "\n",
    "    def start_chat(self):\n",
    "        print(\"Welcome to the component generator!\")\n",
    "        display(self.out)\n",
    "        self.chat(None)\n",
    "\n",
    "    def inject_prompt(self, name):\n",
    "        return (\n",
    "            \"Create a component named \" + name + \". \"\n",
    "            \"Each component must have 5 files: \"\n",
    "            \"<name>.component.ts - containing the primary component code, \"\n",
    "            \"<name>.config.ts - containing the config data, \"\n",
    "            \"<name>.component.html - containing the HTML markup, \"\n",
    "            \"<name>.component.css - stylesheets, \"\n",
    "            \"<name>.component.spec.ts - unit tests. \"\n",
    "            \"Analyze the files within the subfolders: \" + subfolders + \" \"\n",
    "            \"And use them as examples on how each file is referenced from another. \"\n",
    "            \"Strictly follow the following response template within ```\"\n",
    "            \"```\"\n",
    "            \"//<filename>\"\n",
    "            \"<generated code>\"\n",
    "            \"\\\\n\\\\n\"\n",
    "            \"```\"\n",
    "            \"Do not respond back with any additional information.\"\n",
    "        )\n",
    "\n",
    "    def chat(self, _):\n",
    "        if self.name is None:\n",
    "            prompt = \"\"\n",
    "        else:\n",
    "            prompt = self.inject_prompt(self.name.value)\n",
    "            \n",
    "        if 'q' == prompt or 'quit' == prompt or 'Q' == prompt:\n",
    "            with self.out:\n",
    "                print(\"Thank you, that was a nice chat !!\")\n",
    "            return\n",
    "        elif len(prompt) > 0:\n",
    "            with self.out:\n",
    "                thinking = ipw.Label(value=\"Thinking...\")\n",
    "                display(thinking)\n",
    "\n",
    "                try:\n",
    "                    response = self.rag_chain.invoke({\"input\": prompt})\n",
    "                    result = response['answer']\n",
    "                except:\n",
    "                    result = \"Something went wrong!\"\n",
    "                    \n",
    "                thinking.value = \"\"\n",
    "                print(f\"AI: {result}\")\n",
    "                self.name.disabled = True\n",
    "                self.btn.disabled = True\n",
    "                self.name = None\n",
    "\n",
    "        if self.name is None:\n",
    "            with self.out:\n",
    "                self.name = ipw.Text(description=\"You:\", placeholder='q to quit')\n",
    "                self.btn = ipw.Button(description=\"Send\")\n",
    "                self.btn.on_click(self.chat)\n",
    "                display(ipw.Box(children=(self.name, self.btn)))\n",
    "\n",
    "# Start chat to get component name\n",
    "chat = ChatUX(rag_chain)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through adequate tuning, the model successfully generated code that adheres to the established boilerplate. This approach can be seamlessly extended to various types of codebases, including web, mobile, APIs, and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
